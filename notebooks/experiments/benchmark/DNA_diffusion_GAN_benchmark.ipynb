{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install and download"
      ],
      "metadata": {
        "id": "0dosR33d4Q5d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VDoTvvQ392y",
        "outputId": "ba19e96b-90fe-423a-bfab-79b96fcc385c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 18 07:26:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing"
      ],
      "metadata": {
        "id": "tzadEFWb4aNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install pytorch_lightning\n",
        "import os; os.getpid()\n",
        "from scipy.stats import zscore\n",
        "import torch\n",
        "import copy\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "from IPython.display import display\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.modules.activation import ReLU\n",
        "import torch.optim as optim\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm_notebook\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib\n",
        "import math\n",
        "from inspect import isfunction\n",
        "from functools import partial\n",
        "import scipy\n",
        "from scipy.special import rel_entr\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from einops import rearrange\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "from PIL import Image\n",
        "import pytorch_lightning as pl \n",
        "import imageio\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad as torch_grad\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "FfG45jNd4bof",
        "outputId": "7b28dfb2-abd2-4a26-ac84-42e266d44e28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 372 kB/s \n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.8.2-py3-none-any.whl (798 kB)\n",
            "\u001b[K     |████████████████████████████████| 798 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.9.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 60.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.10.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.12.1+cu113)\n",
            "Collecting lightning-utilities==0.3.*\n",
            "  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.50.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (2.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.38.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (3.2.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115940 sha256=35d09d1a4e442a1774e3873c9a3ebbf852d26a11a1aa3d9942844f39d780ed6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, torchmetrics, lightning-utilities, pytorch-lightning\n",
            "Successfully installed fire-0.4.0 lightning-utilities-0.3.0 pytorch-lightning-1.8.2 torchmetrics-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset "
      ],
      "metadata": {
        "id": "OBANVwrV5N8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceDatasetBase(Dataset):\n",
        "    def __init__(self, data_path, sequence_length=200, sequence_encoding=\"polar\", sequence_transform=None, cell_type_transform=None):\n",
        "        super().__init__()\n",
        "        self.data = pd.read_csv(data_path, sep=\"\\t\")\n",
        "        self.sequence_length = sequence_length\n",
        "        self.sequence_encoding = sequence_encoding\n",
        "        self.sequence_transform = sequence_transform\n",
        "        self.cell_type_transform = cell_type_transform\n",
        "        self.alphabet = [\"A\", \"C\", \"T\", \"G\"]\n",
        "        self.check_data_validity()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Iterating through DNA sequences from dataset and one-hot encoding all nucleotides\n",
        "        current_seq = self.data[\"raw_sequence\"][index]\n",
        "        if 'N' not in current_seq: \n",
        "            X_seq = self.encode_sequence(current_seq, encoding=self.sequence_encoding)\n",
        "            \n",
        "            # Reading cell component at current index\n",
        "            X_cell_type = self.data[\"component\"][index]\n",
        "            \n",
        "            if self.sequence_transform is not None:\n",
        "                X_seq = self.sequence_transform(X_seq)\n",
        "            if self.cell_type_transform is not None:\n",
        "                X_cell_type = self.cell_type_transform(X_cell_type)\n",
        "\n",
        "            return X_seq, X_cell_type\n",
        "\n",
        "    def check_data_validity(self):\n",
        "        \"\"\"\n",
        "        Checks if the data is valid.\n",
        "        \"\"\"\n",
        "        if not set(\"\".join(self.data[\"raw_sequence\"])).issubset(set(self.alphabet)):\n",
        "            raise ValueError(f\"Sequence contains invalid characters.\")\n",
        "\n",
        "        uniq_raw_seq_len = self.data[\"raw_sequence\"].str.len().unique()\n",
        "        if len(uniq_raw_seq_len) != 1 or uniq_raw_seq_len[0] != self.sequence_length:\n",
        "            raise ValueError(f\"The sequence length does not match the data.\")\n",
        "\n",
        "    def encode_sequence(self, seq, encoding):\n",
        "        \"\"\"\n",
        "        Encodes a sequence using the given encoding scheme (\"polar\", \"onehot\", \"ordinal\").\n",
        "        \"\"\"\n",
        "        if encoding == \"polar\":\n",
        "            seq = self.one_hot_encode(seq).T\n",
        "            seq[seq == 0] = -1\n",
        "        elif encoding == \"onehot\":\n",
        "            seq = self.one_hot_encode(seq).T\n",
        "        elif encoding == \"ordinal\":\n",
        "            seq = np.array([self.alphabet.index(n) for n in seq])\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown encoding scheme: {encoding}\")\n",
        "        return seq\n",
        "\n",
        "    # Function for one hot encoding each line of the sequence dataset\n",
        "    def one_hot_encode(self, seq):\n",
        "        \"\"\"\n",
        "        One-hot encoding a sequence\n",
        "        \"\"\"\n",
        "        seq_len = len(seq)\n",
        "        seq_array = np.zeros((self.sequence_length, len(self.alphabet)))\n",
        "        for i in range(seq_len):\n",
        "            seq_array[i, self.alphabet.index(seq[i])] = 1\n",
        "        return seq_array\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H-VwhLHE5PYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceDatasetTrain(SequenceDatasetBase):\n",
        "    def __init__(self, data_path=\"\", **kwargs):\n",
        "        super().__init__(data_path=data_path, **kwargs)\n",
        "\n",
        "class SequenceDatasetValidation(SequenceDatasetBase):\n",
        "    def __init__(self, data_path=\"\", **kwargs):\n",
        "        super().__init__(data_path=data_path, **kwargs)\n",
        "\n",
        "class SequenceDatasetTest(SequenceDatasetBase):\n",
        "    def __init__(self, data_path=\"\", **kwargs):\n",
        "        super().__init__(data_path=data_path, **kwargs)\n",
        "\n",
        "\n",
        "class SequenceDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_path=None,\n",
        "        val_path=None,\n",
        "        test_path=None,\n",
        "        sequence_length=200,\n",
        "        sequence_encoding=\"polar\",\n",
        "        sequence_transform=None,\n",
        "        cell_type_transform=None,\n",
        "        batch_size=None,\n",
        "        num_workers=1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.datasets = dict()\n",
        "        self.train_dataloader, self.val_dataloader, self.test_dataloader = None, None, None\n",
        "\n",
        "        if train_path:\n",
        "            self.datasets[\"train\"] = train_path\n",
        "            self.train_dataloader = self._train_dataloader\n",
        "\n",
        "        if val_path:\n",
        "            self.datasets[\"validation\"] = val_path\n",
        "            self.val_dataloader = self._val_dataloader\n",
        "\n",
        "        if test_path:\n",
        "            self.datasets[\"test\"] = test_path\n",
        "            self.test_dataloader = self._test_dataloader\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "        self.sequence_encoding = sequence_encoding\n",
        "        self.sequence_transform = sequence_transform\n",
        "        self.cell_type_transform = cell_type_transform\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self):\n",
        "        if \"train\" in self.datasets:\n",
        "            self.train_data = SequenceDatasetTrain(\n",
        "                data_path=self.datasets[\"train\"],\n",
        "                sequence_length=self.sequence_length,\n",
        "                sequence_encoding=self.sequence_encoding,\n",
        "                sequence_transform=self.sequence_transform,\n",
        "                cell_type_transform=self.cell_type_transform\n",
        "            )\n",
        "        if \"validation\" in self.datasets:\n",
        "            self.val_data = SequenceDatasetValidation(\n",
        "                data_path=self.datasets[\"validation\"],\n",
        "                sequence_length=self.sequence_length,\n",
        "                sequence_encoding=self.sequence_encoding,\n",
        "                sequence_transform=self.sequence_transform,\n",
        "                cell_type_transform=self.cell_type_transform\n",
        "            )\n",
        "        if \"test\" in self.datasets:\n",
        "            self.test_data = SequenceDatasetTest(\n",
        "                data_path=self.datasets[\"test\"],\n",
        "                sequence_length=self.sequence_length,\n",
        "                sequence_encoding=self.sequence_encoding,\n",
        "                sequence_transform=self.sequence_transform,\n",
        "                cell_type_transform=self.cell_type_transform\n",
        "            )\n",
        "\n",
        "    def _train_dataloader(self):\n",
        "        return DataLoader(self.train_data,\n",
        "                          self.batch_size, \n",
        "                          shuffle=True, \n",
        "                          num_workers=self.num_workers, \n",
        "                          pin_memory=True)\n",
        "\n",
        "    def _val_dataloader(self):\n",
        "        return DataLoader(self.val_data,\n",
        "                          self.batch_size, \n",
        "                          shuffle=True,\n",
        "                          num_workers=self.num_workers,\n",
        "                          pin_memory=True)\n",
        "\n",
        "    def _test_dataloader(self):\n",
        "        return DataLoader(self.test_data,\n",
        "                          self.batch_size, \n",
        "                          shuffle=True, \n",
        "                          num_workers=self.num_workers, \n",
        "                          pin_memory=True)"
      ],
      "metadata": {
        "id": "13a5Drpd5VpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the data"
      ],
      "metadata": {
        "id": "vA9bReW8795S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the dataset from https://www.meuleman.org/research/synthseqs/#material"
      ],
      "metadata": {
        "id": "y_oEKw1H8qNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "training set: 160k sequences, 10k per NMF component (chr3-chrY)"
      ],
      "metadata": {
        "id": "Oj4zvdH1-5B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://www.meuleman.org/train_all_classifier_light.csv.gz\n",
        "! gunzip -d /content/train_all_classifier_light.csv.gz"
      ],
      "metadata": {
        "id": "TmErfC4K77bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ff5cd8-e856-4436-cff1-4cd094f52c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-18 07:26:24--  https://www.meuleman.org/train_all_classifier_light.csv.gz\n",
            "Resolving www.meuleman.org (www.meuleman.org)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to www.meuleman.org (www.meuleman.org)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15316727 (15M) [application/gzip]\n",
            "Saving to: ‘train_all_classifier_light.csv.gz’\n",
            "\n",
            "train_all_classifie 100%[===================>]  14.61M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-11-18 07:26:24 (128 MB/s) - ‘train_all_classifier_light.csv.gz’ saved [15316727/15316727]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation set: 16k sequences, 1k per NMF component (chr2 only)"
      ],
      "metadata": {
        "id": "fdSFJOqC-7wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://www.meuleman.org/validation_all_classifier_light.csv.gz\n",
        "! gunzip -d /content/validation_all_classifier_light.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdaVi6Ts-UB9",
        "outputId": "6d5f93a9-8566-46b7-ac63-bf81276335cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-18 07:26:24--  https://www.meuleman.org/validation_all_classifier_light.csv.gz\n",
            "Resolving www.meuleman.org (www.meuleman.org)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to www.meuleman.org (www.meuleman.org)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1517659 (1.4M) [application/gzip]\n",
            "Saving to: ‘validation_all_classifier_light.csv.gz’\n",
            "\n",
            "validation_all_clas 100%[===================>]   1.45M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-11-18 07:26:25 (26.3 MB/s) - ‘validation_all_classifier_light.csv.gz’ saved [1517659/1517659]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test set: 16k sequences, 1k per NMF component (chr1 only)"
      ],
      "metadata": {
        "id": "OhvmhQ2h-_dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://www.meuleman.org/test_all_classifier_light.csv.gz\n",
        "! gunzip -d /content/test_all_classifier_light.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph4Z_CVi-r9m",
        "outputId": "ed775764-011d-45ca-eae3-60ecad346571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-18 07:26:25--  https://www.meuleman.org/test_all_classifier_light.csv.gz\n",
            "Resolving www.meuleman.org (www.meuleman.org)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to www.meuleman.org (www.meuleman.org)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1516076 (1.4M) [application/gzip]\n",
            "Saving to: ‘test_all_classifier_light.csv.gz’\n",
            "\n",
            "\r          test_all_   0%[                    ]       0  --.-KB/s               \rtest_all_classifier 100%[===================>]   1.45M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-11-18 07:26:25 (24.2 MB/s) - ‘test_all_classifier_light.csv.gz’ saved [1516076/1516076]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previews some of the data inside the test set"
      ],
      "metadata": {
        "id": "3R75KJo9-fZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_preview = pd.read_csv('/content/test_all_classifier_light.csv', sep=\"\\t\")\n",
        "data_preview"
      ],
      "metadata": {
        "id": "iv27XSci8CA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b9801296-1e92-4f98-9de1-8bd866216de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      seqname      start        end  DHS_width     summit  total_signal  \\\n",
              "0        chr1    6281480    6281920        440    6281630      8.114064   \n",
              "1        chr1  167472820  167473100        280  167472970      9.213141   \n",
              "2        chr1  203479740  203479940        200  203479840     11.202431   \n",
              "3        chr1   87720660   87720860        200   87720770     19.890169   \n",
              "4        chr1  151313200  151313400        200  151313290      0.507441   \n",
              "...       ...        ...        ...        ...        ...           ...   \n",
              "15995    chr1   86616560   86616760        200   86616670      6.529608   \n",
              "15996    chr1  100233640  100234000        360  100233910      0.918690   \n",
              "15997    chr1    2072180    2072600        420    2072430      1.173570   \n",
              "15998    chr1   90817520   90817860        340   90817660     12.766754   \n",
              "15999    chr1  203116540  203116773        233  203116658      4.524109   \n",
              "\n",
              "       numsamples                                       raw_sequence  \\\n",
              "0               3  TCAAGCCCCCGCCCAGGCGGGCTCTCTCCTGGCCGGGAGTGGCAGC...   \n",
              "1              12  CATGGCCTAGAGAGGATTCTTTGTGTGTCCACACCTGTGTTGCCTG...   \n",
              "2              14  GGAGTCTCTCTAGAGAATCTGCTGTTTATAAACAAATAAATGAGTA...   \n",
              "3              23  TTCCATTCTTTTTGAACTTACTCTCTACCCCGGAAGAATGACAACA...   \n",
              "4               1  AATGAATTCAGGTATTTCATTCTGTCAGTATCAGATAACGCAGGAG...   \n",
              "...           ...                                                ...   \n",
              "15995           8  TAACTTTAAAAAAAAAAAAAAAAAAGAGCTGGGCATGCTGGGAACA...   \n",
              "15996           1  TTAAAAGAGGCAAAGGTAGAGGAGAACAAAGGAAGGAGGAAGTAAC...   \n",
              "15997           1  GTTCAGGCAGGTGTGGGAGGCCAGCCATCAGGAGATGATGCCGTTG...   \n",
              "15998          10  CTGCTTCCTCCACATCTGTCTCCTTCAATGGTATATCATCACCACC...   \n",
              "15999           7  AGAAGGGTGCCCCTGCTCTGCCTCCTCTCACGTCTCCTTTACCCCC...   \n",
              "\n",
              "       component  proportion  \n",
              "0             12    0.734255  \n",
              "1             10    0.696706  \n",
              "2              4    0.975903  \n",
              "3              6    0.792214  \n",
              "4             13    0.869445  \n",
              "...          ...         ...  \n",
              "15995         13    0.887900  \n",
              "15996         16    1.000000  \n",
              "15997         10    0.759222  \n",
              "15998          6    0.800863  \n",
              "15999         12    0.740108  \n",
              "\n",
              "[16000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-148814c6-cf71-42c9-8ab6-43ee922bbcdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seqname</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>DHS_width</th>\n",
              "      <th>summit</th>\n",
              "      <th>total_signal</th>\n",
              "      <th>numsamples</th>\n",
              "      <th>raw_sequence</th>\n",
              "      <th>component</th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chr1</td>\n",
              "      <td>6281480</td>\n",
              "      <td>6281920</td>\n",
              "      <td>440</td>\n",
              "      <td>6281630</td>\n",
              "      <td>8.114064</td>\n",
              "      <td>3</td>\n",
              "      <td>TCAAGCCCCCGCCCAGGCGGGCTCTCTCCTGGCCGGGAGTGGCAGC...</td>\n",
              "      <td>12</td>\n",
              "      <td>0.734255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chr1</td>\n",
              "      <td>167472820</td>\n",
              "      <td>167473100</td>\n",
              "      <td>280</td>\n",
              "      <td>167472970</td>\n",
              "      <td>9.213141</td>\n",
              "      <td>12</td>\n",
              "      <td>CATGGCCTAGAGAGGATTCTTTGTGTGTCCACACCTGTGTTGCCTG...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.696706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chr1</td>\n",
              "      <td>203479740</td>\n",
              "      <td>203479940</td>\n",
              "      <td>200</td>\n",
              "      <td>203479840</td>\n",
              "      <td>11.202431</td>\n",
              "      <td>14</td>\n",
              "      <td>GGAGTCTCTCTAGAGAATCTGCTGTTTATAAACAAATAAATGAGTA...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.975903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chr1</td>\n",
              "      <td>87720660</td>\n",
              "      <td>87720860</td>\n",
              "      <td>200</td>\n",
              "      <td>87720770</td>\n",
              "      <td>19.890169</td>\n",
              "      <td>23</td>\n",
              "      <td>TTCCATTCTTTTTGAACTTACTCTCTACCCCGGAAGAATGACAACA...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.792214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chr1</td>\n",
              "      <td>151313200</td>\n",
              "      <td>151313400</td>\n",
              "      <td>200</td>\n",
              "      <td>151313290</td>\n",
              "      <td>0.507441</td>\n",
              "      <td>1</td>\n",
              "      <td>AATGAATTCAGGTATTTCATTCTGTCAGTATCAGATAACGCAGGAG...</td>\n",
              "      <td>13</td>\n",
              "      <td>0.869445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>chr1</td>\n",
              "      <td>86616560</td>\n",
              "      <td>86616760</td>\n",
              "      <td>200</td>\n",
              "      <td>86616670</td>\n",
              "      <td>6.529608</td>\n",
              "      <td>8</td>\n",
              "      <td>TAACTTTAAAAAAAAAAAAAAAAAAGAGCTGGGCATGCTGGGAACA...</td>\n",
              "      <td>13</td>\n",
              "      <td>0.887900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>chr1</td>\n",
              "      <td>100233640</td>\n",
              "      <td>100234000</td>\n",
              "      <td>360</td>\n",
              "      <td>100233910</td>\n",
              "      <td>0.918690</td>\n",
              "      <td>1</td>\n",
              "      <td>TTAAAAGAGGCAAAGGTAGAGGAGAACAAAGGAAGGAGGAAGTAAC...</td>\n",
              "      <td>16</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>chr1</td>\n",
              "      <td>2072180</td>\n",
              "      <td>2072600</td>\n",
              "      <td>420</td>\n",
              "      <td>2072430</td>\n",
              "      <td>1.173570</td>\n",
              "      <td>1</td>\n",
              "      <td>GTTCAGGCAGGTGTGGGAGGCCAGCCATCAGGAGATGATGCCGTTG...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.759222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>chr1</td>\n",
              "      <td>90817520</td>\n",
              "      <td>90817860</td>\n",
              "      <td>340</td>\n",
              "      <td>90817660</td>\n",
              "      <td>12.766754</td>\n",
              "      <td>10</td>\n",
              "      <td>CTGCTTCCTCCACATCTGTCTCCTTCAATGGTATATCATCACCACC...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.800863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>chr1</td>\n",
              "      <td>203116540</td>\n",
              "      <td>203116773</td>\n",
              "      <td>233</td>\n",
              "      <td>203116658</td>\n",
              "      <td>4.524109</td>\n",
              "      <td>7</td>\n",
              "      <td>AGAAGGGTGCCCCTGCTCTGCCTCCTCTCACGTCTCCTTTACCCCC...</td>\n",
              "      <td>12</td>\n",
              "      <td>0.740108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-148814c6-cf71-42c9-8ab6-43ee922bbcdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-148814c6-cf71-42c9-8ab6-43ee922bbcdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-148814c6-cf71-42c9-8ab6-43ee922bbcdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode data and test loader looping"
      ],
      "metadata": {
        "id": "O2DaM-Ba8STa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 6000\n",
        "LEARNING_RATE = 0.7\n",
        "MOMENTUM = 0.9\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "mtFl7s03PjKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = SequenceDataModule(\n",
        "        train_path = \"/content/train_all_classifier_light.csv\",\n",
        "        val_path = \"/content/validation_all_classifier_light.csv\",\n",
        "        test_path = \"/content/test_all_classifier_light.csv\",\n",
        "        sequence_length = 200,\n",
        "        sequence_encoding = \"polar\",\n",
        "        sequence_transform = None,\n",
        "        cell_type_transform = None,\n",
        "        batch_size = BATCH_SIZE,\n",
        "        num_workers = 0\n",
        "    )"
      ],
      "metadata": {
        "id": "ExynjhD2O3_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data.setup()"
      ],
      "metadata": {
        "id": "bgBUTqO79NXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoded_data.train_data))\n",
        "print(len(encoded_data.val_data))\n",
        "print(len(encoded_data.test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yeWNced9OUM",
        "outputId": "fb391774-9d90-4fd5-feb0-b5530eb1ea4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160000\n",
            "16000\n",
            "16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=encoded_data.train_dataloader()\n",
        "val_loader=encoded_data.val_dataloader()\n",
        "test_loader=encoded_data.test_dataloader()"
      ],
      "metadata": {
        "id": "k8Kt1tYw9RHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s=iter(train_loader)\n",
        "l=next(s)\n",
        "\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JvHp92t9TbN",
        "outputId": "2d915621-a8ec-456d-b3c7-6084b24d3808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[[ 1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1.,  1.,  1.],\n",
            "         [-1.,  1.,  1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ...,  1., -1., -1.]],\n",
            "\n",
            "        [[ 1.,  1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1.,  1.,  ...,  1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1.,  1.,  1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [ 1., -1.,  1.,  ..., -1., -1.,  1.],\n",
            "         [-1.,  1., -1.,  ...,  1.,  1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ...,  1., -1., -1.],\n",
            "         [-1.,  1.,  1.,  ..., -1.,  1., -1.],\n",
            "         [ 1., -1., -1.,  ..., -1., -1.,  1.]],\n",
            "\n",
            "        [[-1.,  1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1.,  1.],\n",
            "         [-1., -1.,  1.,  ..., -1.,  1., -1.],\n",
            "         [ 1., -1., -1.,  ...,  1., -1., -1.]],\n",
            "\n",
            "        [[-1.,  1., -1.,  ...,  1.,  1.,  1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1.,  1.,  ..., -1., -1., -1.],\n",
            "         [ 1., -1., -1.,  ..., -1., -1., -1.]]], dtype=torch.float64), tensor([ 8, 15, 16,  1, 11,  5,  4,  7,  2, 11, 15, 11, 16, 13, 12,  8])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index,(x,y) in enumerate(train_loader):\n",
        "  print(x.shape) #(bs,4,len)\n",
        "  print(y.shape) # (bs)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU9aRsqn9Yyt",
        "outputId": "533c0046-4553-4ff7-ec29-d79dbc7124b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 4, 200])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WGAN-GP"
      ],
      "metadata": {
        "id": "vlSQ0FSP5w_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.biorxiv.org/content/10.1101/2022.07.26.501466v1.full.pdf#page=10\n",
        "Generative Adversarial Network\n",
        "To train a GAN model, we used Wasserstein GAN architecture with gradient penalty similar to earlier work. \n",
        "The model consists of two parts; generator and discriminator. Generator takes noise as input (size is 128), \n",
        "followed by a dense layer with 64,000 (500 * 128) units with ELU activation, a reshape layer (500, 128), \n",
        "a convolution tower of 5 convolution blocks with skip connections, \n",
        "a 1D convolution layer with 4 filters with kernel width 1, and finally a SOFTMAX activation layer. \n",
        "The output of the generator is a 500 × 4 matrix, which represents one-hot encoded DNA sequence. \n",
        "\n",
        "Discriminator takes 500 bp one-hot encoded DNA sequence as input (real or fake), \n",
        "followed by a 1D convolution layer with 128 filters with kernel width 1, \n",
        "a convolution tower of 5 convolution blocks with skip connections, a flatten layer, \n",
        "and finally a dense layer with 1 unit.\n",
        "Each block in the convolution tower consists of a RELU activation layer \n",
        "followed by 1D convolution with 128 filters with kernel width 5. \n",
        "The noise is generated by the numpy.random.normal(0, 1, (batch_size, 128)) command. We used a batch size of 128. \n",
        "For every train_on_batch iteration of the generator, we performed 10 train_on_batch iteration for the discriminator. \n",
        "We used Adam optimizer with learning_rate of 0.0001, beta_1 of 0.5, and beta_2 of 0.9. \n",
        "We trained the models for around 260,000 batch training iteration for KC and \n",
        "around 160,000 batch training iteration for MEL.\n"
      ],
      "metadata": {
        "id": "qgYRymHH8u4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE_OF_NOISE_INPUT = 128\n",
        "SIZE_OF_FEATURE_MAP = 128\n",
        "DNA_BP = 200\n",
        "SIZE_OF_HIDDEN_LAYERS = DNA_BP*SIZE_OF_NOISE_INPUT\n",
        "NUM_OF_1D_CONV_FILTERS = 4\n",
        "NUM_OF_CONV_1D = 5"
      ],
      "metadata": {
        "id": "zVxP5RAePlSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.linears = nn.Sequential(\n",
        "            nn.Linear(SIZE_OF_NOISE_INPUT, SIZE_OF_HIDDEN_LAYERS),\n",
        "            nn.ReLU()  # replace ELU with RELU\n",
        "            #nn.Dropout()\n",
        "        )\n",
        "\n",
        "        self.relu=nn.ReLU()\n",
        "        self.conv_1d= nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5,stride=1, padding=2, dilation=1)\n",
        "        self.final_conv_1d=nn.Conv1d(in_channels=128,out_channels=4,kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        dense_output = self.linears(x)\n",
        "        conv_1d_input = torch.reshape(dense_output, (dense_output.shape[0], SIZE_OF_NOISE_INPUT, DNA_BP )) \n",
        "      \n",
        "        for i in range(NUM_OF_CONV_1D):  # a convolution tower of 5 convolution blocks with skip connections           \n",
        "            if i==0:\n",
        "              residual = conv_1d_input\n",
        "              output = F.relu(self.conv_1d(conv_1d_input))\n",
        "              output = output.clone()\n",
        "              output += residual\n",
        "              \n",
        "            else:\n",
        "              residual=output\n",
        "              output = F.relu(self.conv_1d(output))\n",
        "              output = output.clone()\n",
        "              output += residual\n",
        "       \n",
        "        output = self.final_conv_1d(output)\n",
        "        output = F.softmax(output,dim=1)\n",
        "            \n",
        "        return output\n",
        "\n",
        "    def sample_latent(self, num_samples):\n",
        "        return torch.randn((num_samples, self.latent_dim))"
      ],
      "metadata": {
        "id": "osiPt2bW8Vod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gen_test=Generator()\n",
        "normal_dist=torch.randn(BATCH_SIZE,128)\n",
        "gen_dna=Gen_test(normal_dist) # final output should be (200,4) or (4,200) matrix"
      ],
      "metadata": {
        "id": "DDfoi_Ug0CFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessible elements are typically around 200bp in length, and using larger regions could conflate things by combining multiple neighboring sites.\n",
        "\n",
        "For initial testing purpose, we will use @meuleman's 200 bp dna dataset"
      ],
      "metadata": {
        "id": "HcKoUTq8feDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_dna.shape"
      ],
      "metadata": {
        "id": "txjniZW1Ln2X",
        "outputId": "a3b35e47-5d9d-42a8-9d4a-e9da89c4f69f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 4, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What they say about the discriminator:\n",
        "\n",
        "\n",
        "Discriminator\t takes\t500\tbp\tone-hot\tencoded\tDNA\tsequence\tas\tinput\t(real or\tfake),\tfollowed\tby\ta\t1D\tconvolution\tlayer\twith\t128 filters\t with\tkernel\twidth\t1,\ta\tconvolution\ttower\tof\t5\tconvolution\t blocks\twith\t skip\t connections,\ta\t flatten\tlayer,\tand\t finally\ta\t  dense\tlayer\twith\t1\tunit. Each\t block\t in\t the\t convolution\t tower\t consists\t of\t a\t RELU\t activation\tlayer\tfollowed\tby\t1D\tconvolution\twith\t128\tfilters\t with\t kernel\t width\t 5.\t "
      ],
      "metadata": {
        "id": "Gfk8_IRJIRKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.first_conv = nn.Conv1d(in_channels=4,out_channels=128,kernel_size=1)\n",
        "        self.conv_1d = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=5,stride=1, padding=2, dilation=1)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(SIZE_OF_FEATURE_MAP*DNA_BP,1),\n",
        "            nn.ReLU()  # replace ELU with RELU\n",
        "            #nn.Dropout()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):       \n",
        "        conv_1d_input = self.first_conv(x)\n",
        "\n",
        "        for i in range(NUM_OF_CONV_1D):  # a convolution tower of 5 convolution blocks with skip connections\n",
        "          if i==0:\n",
        "            residual = conv_1d_input\n",
        "            output = F.relu(self.conv_1d(conv_1d_input))\n",
        "            output = output.clone()\n",
        "            output += residual\n",
        "\n",
        "          else:\n",
        "            residual = output\n",
        "            output = F.relu(self.conv_1d(output))\n",
        "            output = output.clone()\n",
        "            output += residual\n",
        "\n",
        "        output = output.view(output.shape[0],-1)\n",
        "        output = self.linear(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "0mXI6AfvILKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dis=Discriminator()\n",
        "test_input=dis(gen_dna)\n",
        "print(test_input.shape)"
      ],
      "metadata": {
        "id": "jIzGrJn5LeG7",
        "outputId": "24a1bd82-48d5-4cf3-de4e-59ace19dfe5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainer"
      ],
      "metadata": {
        "id": "XQAtUh9n9Anp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See https://zhuanlan.zhihu.com/p/25071913 for a chinese explanation on WGAN-GP\n",
        "# Reused from https://github.com/EmilienDupont/wgan-gp/blob/ef82364f2a2ec452a52fbf4a739f95039ae76fe3/training.py\n",
        "class Trainer:\n",
        "    def __init__(self, generator, discriminator, gen_optimizer, dis_optimizer,\n",
        "                 gp_weight=10, critic_iterations=5, print_every=50,\n",
        "                 use_cuda=False):\n",
        "        self.G = generator\n",
        "        self.G_opt = gen_optimizer\n",
        "        self.D = discriminator\n",
        "        self.D_opt = dis_optimizer\n",
        "        self.losses = {'G': [], 'D': [], 'GP': [], 'gradient_norm': []}\n",
        "        self.num_steps = 0\n",
        "        self.use_cuda = use_cuda\n",
        "        self.gp_weight = gp_weight\n",
        "        self.critic_iterations = critic_iterations\n",
        "        self.print_every = print_every\n",
        "\n",
        "        if self.use_cuda:\n",
        "            self.G.cuda()\n",
        "            self.D.cuda()\n",
        "\n",
        "    def _critic_train_iteration(self, data):\n",
        "        \"\"\" \"\"\"\n",
        "        # Get generated data\n",
        "        batch_size = data.size()[0]\n",
        "        generated_data = self.sample_generator(batch_size)\n",
        "\n",
        "        # Calculate probabilities on real and generated data\n",
        "        data = Variable(data).float()\n",
        "        if self.use_cuda:\n",
        "            data = data.cuda()\n",
        "        d_real = self.D(data)\n",
        "        d_generated = self.D(generated_data)\n",
        "\n",
        "        # Get gradient penalty\n",
        "        gradient_penalty = self._gradient_penalty(data, generated_data)\n",
        "        self.losses['GP'].append(gradient_penalty)#.data[0])\n",
        "\n",
        "        # Create total loss and optimize\n",
        "        self.D_opt.zero_grad()\n",
        "        d_loss = d_generated.mean() - d_real.mean() + gradient_penalty\n",
        "        d_loss.backward()\n",
        "\n",
        "        self.D_opt.step()\n",
        "\n",
        "        # Record loss\n",
        "        self.losses['D'].append(d_loss)#.data[0])\n",
        "\n",
        "    def _generator_train_iteration(self, data):\n",
        "        \"\"\" \"\"\"\n",
        "        self.G_opt.zero_grad()\n",
        "\n",
        "        # Get generated data\n",
        "        batch_size = data.size()[0]\n",
        "        generated_data = self.sample_generator(batch_size)\n",
        "\n",
        "        # Calculate loss and optimize\n",
        "        d_generated = self.D(generated_data)\n",
        "        g_loss = - d_generated.mean()\n",
        "        g_loss.backward()\n",
        "        self.G_opt.step()\n",
        "\n",
        "        # Record loss\n",
        "        self.losses['G'].append(g_loss)#.data[0])\n",
        "\n",
        "    def _gradient_penalty(self, real_data, generated_data):\n",
        "        batch_size = real_data.size()[0]\n",
        "\n",
        "        # https://ai.stackexchange.com/questions/34926/why-do-we-use-a-linear-interpolation-of-fake-and-real-data-to-penalize-the-gradi\n",
        "        # Calculates interpolation\n",
        "        alpha = torch.rand(batch_size, 1, 1)\n",
        "        alpha = alpha.expand_as(real_data)\n",
        "        if self.use_cuda:\n",
        "            alpha = alpha.cuda()\n",
        "        interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
        "        interpolated = Variable(interpolated, requires_grad=True)\n",
        "        if self.use_cuda:\n",
        "            interpolated = interpolated.cuda()\n",
        "\n",
        "        # Calculate probability of interpolated examples\n",
        "        prob_interpolated = self.D(interpolated)\n",
        "\n",
        "        # Calculate gradients of probabilities with respect to examples\n",
        "        gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
        "                               grad_outputs=torch.ones(prob_interpolated.size()).cuda()\n",
        "                               if self.use_cuda else torch.ones(prob_interpolated.size()),\n",
        "                               create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "        # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
        "        # so flatten to easily take norm per example in batch\n",
        "        gradients = gradients.view(batch_size, -1)\n",
        "        self.losses['gradient_norm'].append(gradients.norm(2, dim=1).mean())#.data[0])\n",
        "\n",
        "        # Derivatives of the gradient close to 0 can cause problems because of\n",
        "        # the square root, so manually calculate norm and add epsilon\n",
        "        gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
        "\n",
        "        # Return gradient penalty\n",
        "        return self.gp_weight * ((gradients_norm - 1) ** 2).mean()\n",
        "\n",
        "    def _train_epoch(self, data_loader):\n",
        "        for i, data in enumerate(data_loader):\n",
        "            self.num_steps += 1\n",
        "            self._critic_train_iteration(data[0])\n",
        "            # Only update generator every |critic_iterations| iterations\n",
        "            if self.num_steps % self.critic_iterations == 0:\n",
        "                self._generator_train_iteration(data[0])\n",
        "\n",
        "            if i % self.print_every == 0:\n",
        "                print(\"Iteration {}\".format(i + 1))\n",
        "                print(\"D: {}\".format(self.losses['D'][-1]))\n",
        "                print(\"GP: {}\".format(self.losses['GP'][-1]))\n",
        "                print(\"Gradient norm: {}\".format(self.losses['gradient_norm'][-1]))\n",
        "                if self.num_steps > self.critic_iterations:\n",
        "                    print(\"G: {}\".format(self.losses['G'][-1]))\n",
        "\n",
        "    def train(self, data_loader, epochs, save_training_gif=True):\n",
        "        if save_training_gif:\n",
        "            # Fix latents to see how image generation improves during training\n",
        "            fixed_latents = Variable(self.G.sample_latent(64))\n",
        "            if self.use_cuda:\n",
        "                fixed_latents = fixed_latents.cuda()\n",
        "            training_progress_images = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"\\nEpoch {}\".format(epoch + 1))\n",
        "            self._train_epoch(data_loader)\n",
        "\n",
        "            if save_training_gif:\n",
        "                # Generate batch of images and convert to grid\n",
        "                img_grid = make_grid(self.G(fixed_latents).cpu().data)\n",
        "                # Convert to numpy and transpose axes to fit imageio convention\n",
        "                # i.e. (width, height, channels)\n",
        "                img_grid = np.transpose(img_grid.numpy(), (1, 2, 0))\n",
        "                # Add image grid to training progress\n",
        "                training_progress_images.append(img_grid)\n",
        "\n",
        "        if save_training_gif:\n",
        "            imageio.mimsave('./training_{}_epochs.gif'.format(epochs),\n",
        "                            training_progress_images)\n",
        "\n",
        "    def sample_generator(self, num_samples):\n",
        "        latent_samples = Variable(self.G.sample_latent(num_samples))\n",
        "        if self.use_cuda:\n",
        "            latent_samples = latent_samples.cuda()\n",
        "        #print(\"size of latent_samples = \", latent_samples.shape)\n",
        "        generated_data = self.G(latent_samples)\n",
        "        #print(\"size of generated_data = \", generated_data.shape)\n",
        "        return generated_data\n",
        "\n",
        "    def sample(self, num_samples):\n",
        "        generated_data = self.sample_generator(num_samples)\n",
        "        # Remove color channel\n",
        "        return generated_data.data.cpu().numpy()#[:, 0, :, :]\n"
      ],
      "metadata": {
        "id": "BeNX4Vf58-Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing network"
      ],
      "metadata": {
        "id": "s35JFFAl9CXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator=Generator(latent_dim = SIZE_OF_NOISE_INPUT)\n",
        "discriminator=Discriminator()\n",
        "\n",
        "print(generator)\n",
        "print(discriminator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b51SC6sxh29B",
        "outputId": "18360b55-fb9d-41b2-94a6-3e6717ae7660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (linears): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=25600, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (relu): ReLU()\n",
            "  (conv_1d): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (final_conv_1d): Conv1d(128, 4, kernel_size=(1,), stride=(1,))\n",
            ")\n",
            "Discriminator(\n",
            "  (first_conv): Conv1d(4, 128, kernel_size=(1,), stride=(1,))\n",
            "  (conv_1d): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (linear): Sequential(\n",
            "    (0): Linear(in_features=25600, out_features=1, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_optimizer=torch.optim.Adam(generator.parameters(), amsgrad=True, lr=0.001)\n",
        "dis_optimizer=torch.optim.Adam(discriminator.parameters(), amsgrad=True, lr=0.001)"
      ],
      "metadata": {
        "id": "PMn-bOBGbP3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = encoded_data.train_dataloader()\n",
        "val_loader = encoded_data.val_dataloader()\n",
        "test_loader = encoded_data.test_dataloader()"
      ],
      "metadata": {
        "id": "5Lmhf9BZh581"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "trainer = Trainer(generator,discriminator,gen_optimizer,dis_optimizer,use_cuda=USE_CUDA)"
      ],
      "metadata": {
        "id": "dMTNhOpdh-Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'save_training_gif = False' is sufficient for now, let's get some genomic person to check this part later\n",
        "# needs to adapt 'fixed_latents' stuff to plot intermediary figures of the generated DNA sequences\n",
        "epochs = 10\n",
        "trainer.train(train_loader, epochs, save_training_gif = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX_7hVOKiCET",
        "outputId": "f241dd52-61b2-40b3-88ba-90e181b6635a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Iteration 1\n",
            "D: 1.2670364379882812\n",
            "GP: 1.2819125652313232\n",
            "Gradient norm: 0.8303024768829346\n",
            "Iteration 51\n",
            "D: -48.8807487487793\n",
            "GP: 13.572396278381348\n",
            "Gradient norm: 2.1551895141601562\n",
            "G: -30.87215232849121\n",
            "Iteration 101\n",
            "D: -49.768341064453125\n",
            "GP: 22.538537979125977\n",
            "Gradient norm: 2.4976038932800293\n",
            "G: -18.478038787841797\n",
            "Iteration 151\n",
            "D: -43.333885192871094\n",
            "GP: 21.27605438232422\n",
            "Gradient norm: 2.4570722579956055\n",
            "G: -12.298599243164062\n",
            "Iteration 201\n",
            "D: -48.06883239746094\n",
            "GP: 19.276140213012695\n",
            "Gradient norm: 2.38116455078125\n",
            "G: -2.7971625328063965\n",
            "Iteration 251\n",
            "D: -42.80603790283203\n",
            "GP: 23.888444900512695\n",
            "Gradient norm: 2.5449233055114746\n",
            "G: -27.403606414794922\n",
            "Iteration 301\n",
            "D: -46.64417266845703\n",
            "GP: 14.609437942504883\n",
            "Gradient norm: 2.202986717224121\n",
            "G: -0.9619186520576477\n",
            "Iteration 351\n",
            "D: -42.83174514770508\n",
            "GP: 17.83197784423828\n",
            "Gradient norm: 2.3349967002868652\n",
            "G: -8.67154312133789\n",
            "Iteration 401\n",
            "D: -46.29710388183594\n",
            "GP: 20.61407470703125\n",
            "Gradient norm: 2.428495407104492\n",
            "G: -16.75168228149414\n",
            "Iteration 451\n",
            "D: -45.185020446777344\n",
            "GP: 24.90160369873047\n",
            "Gradient norm: 2.5665647983551025\n",
            "G: -27.565027236938477\n",
            "Iteration 501\n",
            "D: -46.29977035522461\n",
            "GP: 19.557392120361328\n",
            "Gradient norm: 2.394106864929199\n",
            "G: -22.765514373779297\n",
            "Iteration 551\n",
            "D: -48.04426956176758\n",
            "GP: 23.070690155029297\n",
            "Gradient norm: 2.5169286727905273\n",
            "G: -12.434463500976562\n",
            "Iteration 601\n",
            "D: -50.05152893066406\n",
            "GP: 21.85634422302246\n",
            "Gradient norm: 2.4612417221069336\n",
            "G: -25.5335636138916\n",
            "Iteration 651\n",
            "D: -46.549991607666016\n",
            "GP: 14.461512565612793\n",
            "Gradient norm: 2.202322483062744\n",
            "G: -4.189102649688721\n",
            "Iteration 701\n",
            "D: -47.30096435546875\n",
            "GP: 16.825773239135742\n",
            "Gradient norm: 2.2965922355651855\n",
            "G: -8.51091194152832\n",
            "Iteration 751\n",
            "D: -40.03571701049805\n",
            "GP: 13.126063346862793\n",
            "Gradient norm: 2.126272678375244\n",
            "G: -0.0\n",
            "Iteration 801\n",
            "D: -44.8299560546875\n",
            "GP: 19.560073852539062\n",
            "Gradient norm: 2.139206647872925\n",
            "G: -0.0\n",
            "Iteration 851\n",
            "D: -47.806640625\n",
            "GP: 24.58746337890625\n",
            "Gradient norm: 2.5534486770629883\n",
            "G: -6.807328224182129\n",
            "Iteration 901\n",
            "D: -48.686279296875\n",
            "GP: 24.243263244628906\n",
            "Gradient norm: 2.5353305339813232\n",
            "G: -3.659879446029663\n",
            "Iteration 951\n",
            "D: -50.68034362792969\n",
            "GP: 19.210838317871094\n",
            "Gradient norm: 2.3831334114074707\n",
            "G: -0.7214078307151794\n",
            "Iteration 1001\n",
            "D: -50.420921325683594\n",
            "GP: 18.929353713989258\n",
            "Gradient norm: 2.3731751441955566\n",
            "G: -1.8901371955871582\n",
            "Iteration 1051\n",
            "D: -49.7545051574707\n",
            "GP: 20.308002471923828\n",
            "Gradient norm: 2.4147138595581055\n",
            "G: -6.136759281158447\n",
            "Iteration 1101\n",
            "D: -49.462764739990234\n",
            "GP: 22.513355255126953\n",
            "Gradient norm: 2.4943604469299316\n",
            "G: -8.570016860961914\n",
            "Iteration 1151\n",
            "D: -49.96070098876953\n",
            "GP: 21.70274543762207\n",
            "Gradient norm: 2.4666500091552734\n",
            "G: -4.833559036254883\n",
            "Iteration 1201\n",
            "D: -55.10444641113281\n",
            "GP: 20.383150100708008\n",
            "Gradient norm: 2.411592960357666\n",
            "G: -1.5366122722625732\n",
            "Iteration 1251\n",
            "D: -51.82807540893555\n",
            "GP: 20.348339080810547\n",
            "Gradient norm: 2.417719841003418\n",
            "G: -5.659937858581543\n",
            "Iteration 1301\n",
            "D: -56.138126373291016\n",
            "GP: 24.76082992553711\n",
            "Gradient norm: 2.562272548675537\n",
            "G: -5.728889465332031\n",
            "Iteration 1351\n",
            "D: -53.36588668823242\n",
            "GP: 26.853939056396484\n",
            "Gradient norm: 2.6264872550964355\n",
            "G: -3.7443056106567383\n",
            "Iteration 1401\n",
            "D: -54.436195373535156\n",
            "GP: 20.101394653320312\n",
            "Gradient norm: 2.410869598388672\n",
            "G: -1.603386640548706\n",
            "Iteration 1451\n",
            "D: -53.41053009033203\n",
            "GP: 26.111434936523438\n",
            "Gradient norm: 2.611006736755371\n",
            "G: -5.073277950286865\n",
            "Iteration 1501\n",
            "D: -53.17440414428711\n",
            "GP: 24.997333526611328\n",
            "Gradient norm: 2.5699963569641113\n",
            "G: -3.4679787158966064\n",
            "Iteration 1551\n",
            "D: -51.83458709716797\n",
            "GP: 23.786611557006836\n",
            "Gradient norm: 2.540083169937134\n",
            "G: -0.0\n",
            "Iteration 1601\n",
            "D: -52.823974609375\n",
            "GP: 24.383745193481445\n",
            "Gradient norm: 2.560464382171631\n",
            "G: -0.32733389735221863\n",
            "Iteration 1651\n",
            "D: -54.5523796081543\n",
            "GP: 22.510311126708984\n",
            "Gradient norm: 2.494286060333252\n",
            "G: -0.6327855587005615\n",
            "Iteration 1701\n",
            "D: -57.943321228027344\n",
            "GP: 22.58702278137207\n",
            "Gradient norm: 2.4916279315948486\n",
            "G: -0.4182058572769165\n",
            "Iteration 1751\n",
            "D: -53.644508361816406\n",
            "GP: 29.395544052124023\n",
            "Gradient norm: 2.697080612182617\n",
            "G: -4.49039363861084\n",
            "Iteration 1801\n",
            "D: -54.787864685058594\n",
            "GP: 21.827566146850586\n",
            "Gradient norm: 2.468173027038574\n",
            "G: -2.647860050201416\n",
            "Iteration 1851\n",
            "D: -55.21666717529297\n",
            "GP: 22.783185958862305\n",
            "Gradient norm: 2.5007553100585938\n",
            "G: -3.356264352798462\n",
            "Iteration 1901\n",
            "D: -55.89336395263672\n",
            "GP: 21.3924560546875\n",
            "Gradient norm: 2.457940101623535\n",
            "G: -1.4499154090881348\n",
            "Iteration 1951\n",
            "D: -53.81098937988281\n",
            "GP: 20.231855392456055\n",
            "Gradient norm: 2.414890766143799\n",
            "G: -0.4971034526824951\n",
            "Iteration 2001\n",
            "D: -55.57529067993164\n",
            "GP: 21.195453643798828\n",
            "Gradient norm: 2.4372682571411133\n",
            "G: -3.372835159301758\n",
            "Iteration 2051\n",
            "D: -50.62220764160156\n",
            "GP: 24.467580795288086\n",
            "Gradient norm: 2.5565128326416016\n",
            "G: -5.3901214599609375\n",
            "Iteration 2101\n",
            "D: -50.69873809814453\n",
            "GP: 22.655853271484375\n",
            "Gradient norm: 2.4907214641571045\n",
            "G: -4.412640571594238\n",
            "Iteration 2151\n",
            "D: -48.18012237548828\n",
            "GP: 13.861644744873047\n",
            "Gradient norm: 2.1629106998443604\n",
            "G: -4.705391883850098\n",
            "Iteration 2201\n",
            "D: -48.38066864013672\n",
            "GP: 16.455018997192383\n",
            "Gradient norm: 2.271778106689453\n",
            "G: -3.448197841644287\n",
            "Iteration 2251\n",
            "D: -47.610931396484375\n",
            "GP: 20.660743713378906\n",
            "Gradient norm: 2.423495292663574\n",
            "G: -7.364772796630859\n",
            "Iteration 2301\n",
            "D: -49.47126388549805\n",
            "GP: 25.139270782470703\n",
            "Gradient norm: 2.5748167037963867\n",
            "G: -3.082489252090454\n",
            "Iteration 2351\n",
            "D: -49.09853744506836\n",
            "GP: 22.20407485961914\n",
            "Gradient norm: 2.480821132659912\n",
            "G: -4.978525161743164\n",
            "Iteration 2401\n",
            "D: -49.966148376464844\n",
            "GP: 18.960289001464844\n",
            "Gradient norm: 2.369784355163574\n",
            "G: -0.22347590327262878\n",
            "Iteration 2451\n",
            "D: -49.58857727050781\n",
            "GP: 19.32924461364746\n",
            "Gradient norm: 2.380557060241699\n",
            "G: -2.1929779052734375\n",
            "Iteration 2501\n",
            "D: -53.63566970825195\n",
            "GP: 16.963619232177734\n",
            "Gradient norm: 2.270333766937256\n",
            "G: -5.061461925506592\n",
            "Iteration 2551\n",
            "D: -44.91181182861328\n",
            "GP: 22.656946182250977\n",
            "Gradient norm: 2.4939937591552734\n",
            "G: -8.101079940795898\n",
            "Iteration 2601\n",
            "D: -46.32012176513672\n",
            "GP: 16.439496994018555\n",
            "Gradient norm: 2.2768893241882324\n",
            "G: -0.9594305753707886\n",
            "Iteration 2651\n",
            "D: -47.17241668701172\n",
            "GP: 21.499910354614258\n",
            "Gradient norm: 2.452153205871582\n",
            "G: -2.3001561164855957\n",
            "Iteration 2701\n",
            "D: -48.34606170654297\n",
            "GP: 20.471315383911133\n",
            "Gradient norm: 2.423689842224121\n",
            "G: -1.0866016149520874\n",
            "Iteration 2751\n",
            "D: -45.79224395751953\n",
            "GP: 18.5521297454834\n",
            "Gradient norm: 2.3497612476348877\n",
            "G: -1.6279525756835938\n",
            "Iteration 2801\n",
            "D: -50.86933135986328\n",
            "GP: 19.00068473815918\n",
            "Gradient norm: 2.3572452068328857\n",
            "G: -3.8006603717803955\n",
            "Iteration 2851\n",
            "D: -46.18172836303711\n",
            "GP: 37.18197250366211\n",
            "Gradient norm: 2.903742551803589\n",
            "G: -5.815423488616943\n",
            "Iteration 2901\n",
            "D: -47.95075988769531\n",
            "GP: 27.900304794311523\n",
            "Gradient norm: 2.652118682861328\n",
            "G: -3.652596950531006\n",
            "Iteration 2951\n",
            "D: -48.3178596496582\n",
            "GP: 23.592662811279297\n",
            "Gradient norm: 2.5300049781799316\n",
            "G: -3.7707345485687256\n",
            "Iteration 3001\n",
            "D: -50.30340576171875\n",
            "GP: 22.7889347076416\n",
            "Gradient norm: 2.492905616760254\n",
            "G: -4.739743232727051\n",
            "Iteration 3051\n",
            "D: -47.69622802734375\n",
            "GP: 19.71156120300293\n",
            "Gradient norm: 2.3948442935943604\n",
            "G: -2.2967309951782227\n",
            "Iteration 3101\n",
            "D: -49.34864044189453\n",
            "GP: 22.063405990600586\n",
            "Gradient norm: 2.468351125717163\n",
            "G: -5.875409126281738\n",
            "Iteration 3151\n",
            "D: -47.63187789916992\n",
            "GP: 24.524723052978516\n",
            "Gradient norm: 2.5515623092651367\n",
            "G: -4.7785563468933105\n",
            "Iteration 3201\n",
            "D: -49.11039733886719\n",
            "GP: 18.976821899414062\n",
            "Gradient norm: 2.3650174140930176\n",
            "G: -2.365683078765869\n",
            "Iteration 3251\n",
            "D: -47.34881591796875\n",
            "GP: 27.846946716308594\n",
            "Gradient norm: 2.655697822570801\n",
            "G: -3.662144184112549\n",
            "Iteration 3301\n",
            "D: -47.92115020751953\n",
            "GP: 20.899763107299805\n",
            "Gradient norm: 2.3055150508880615\n",
            "G: -0.015117969363927841\n",
            "Iteration 3351\n",
            "D: -50.109554290771484\n",
            "GP: 17.889225006103516\n",
            "Gradient norm: 2.313779592514038\n",
            "G: -5.8785600662231445\n",
            "Iteration 3401\n",
            "D: -48.90263366699219\n",
            "GP: 23.68866729736328\n",
            "Gradient norm: 2.5185022354125977\n",
            "G: -2.1393346786499023\n",
            "Iteration 3451\n",
            "D: -47.77825927734375\n",
            "GP: 21.89650535583496\n",
            "Gradient norm: 2.4700984954833984\n",
            "G: -3.5200531482696533\n",
            "Iteration 3501\n",
            "D: -47.90005874633789\n",
            "GP: 22.709529876708984\n",
            "Gradient norm: 2.492995262145996\n",
            "G: -3.2875466346740723\n",
            "Iteration 3551\n",
            "D: -49.745765686035156\n",
            "GP: 20.159378051757812\n",
            "Gradient norm: 2.406635284423828\n",
            "G: -5.9993510246276855\n",
            "Iteration 3601\n",
            "D: -45.13599395751953\n",
            "GP: 27.43585968017578\n",
            "Gradient norm: 2.6505942344665527\n",
            "G: -6.135685920715332\n",
            "Iteration 3651\n",
            "D: -50.704471588134766\n",
            "GP: 21.796886444091797\n",
            "Gradient norm: 2.4634904861450195\n",
            "G: -5.868144512176514\n",
            "Iteration 3701\n",
            "D: -48.24131774902344\n",
            "GP: 24.350563049316406\n",
            "Gradient norm: 2.54136323928833\n",
            "G: -2.686713218688965\n",
            "Iteration 3751\n",
            "D: -49.86045837402344\n",
            "GP: 16.379030227661133\n",
            "Gradient norm: 2.268401622772217\n",
            "G: -3.4280362129211426\n",
            "Iteration 3801\n",
            "D: -49.004512786865234\n",
            "GP: 22.125049591064453\n",
            "Gradient norm: 2.4775619506835938\n",
            "G: -4.444873809814453\n",
            "Iteration 3851\n",
            "D: -47.090728759765625\n",
            "GP: 23.39582061767578\n",
            "Gradient norm: 2.51898193359375\n",
            "G: -6.773324966430664\n",
            "Iteration 3901\n",
            "D: -49.338706970214844\n",
            "GP: 18.484113693237305\n",
            "Gradient norm: 2.333902359008789\n",
            "G: -4.505059719085693\n",
            "Iteration 3951\n",
            "D: -49.128501892089844\n",
            "GP: 21.229507446289062\n",
            "Gradient norm: 2.446939706802368\n",
            "G: -2.301279067993164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "name = 'dna_model'\n",
        "torch.save(trainer.G.state_dict(), './gen_' + name + '.pt')\n",
        "torch.save(trainer.D.state_dict(), './dis_' + name + '.pt')"
      ],
      "metadata": {
        "id": "bNhsdg0nidKw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}